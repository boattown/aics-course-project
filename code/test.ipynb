{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and comparing the probes for BERT and VisualBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models import Probe\n",
    "from dataset import create_df, get_gold_data, get_bert_embedding_dict, get_visual_bert_embedding_dict, get_lists_and_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df('../data/affordance_annotations.txt')\n",
    "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "unique_objects, unique_affordances, word_to_index, index_to_word = get_lists_and_dicts(df)\n",
    "train_pairs = get_gold_data(shuffled_df[:42])\n",
    "val_pairs = get_gold_data(shuffled_df[42:52])\n",
    "test_pairs = get_gold_data(shuffled_df[52:])\n",
    "bert_word_to_embedding = get_bert_embedding_dict([train_pairs + val_pairs + test_pairs])\n",
    "visual_bert_word_to_embedding = get_visual_bert_embedding_dict([train_pairs + val_pairs + test_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dict_objects = dict.fromkeys(unique_objects, 0)\n",
    "for index, row in df.iterrows():\n",
    "        for i, value in enumerate(row):\n",
    "            if type(value) == str:\n",
    "                pass\n",
    "            else:\n",
    "                baseline_dict_objects[row[0]] += value\n",
    "                \n",
    "baseline_total_objects = 0\n",
    "for k,v in baseline_dict_objects.items():\n",
    "    baseline_dict_objects[k] = np.round((v * 100)/15, 2)\n",
    "    baseline_total_objects += v\n",
    "\n",
    "baseline_total_objects = np.round((baseline_total_objects/(15*62))*100,2)\n",
    "print(f'{100-baseline_total_objects} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dict_affordances = dict.fromkeys(unique_affordances, 0)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for k in baseline_dict_affordances.keys():\n",
    "        baseline_dict_affordances[k] += row[k]\n",
    "        \n",
    "baseline_total_affordances = 0\n",
    "for k,v in baseline_dict_affordances.items():\n",
    "    baseline_dict_affordances[k] = np.round((v * 100)/62, 2)\n",
    "    baseline_total_affordances += v\n",
    "\n",
    "baseline_total_affordances = np.round((baseline_total_affordances/(15*62))*100,2)\n",
    "print(f'{100-baseline_total_objects} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the BERT Probe on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "bert_probe = Probe().to(device)\n",
    "bert_probe.load_state_dict(torch.load(\"../model_bert_probe|epochs_2000|batch_size_64|learning_rate_0.005\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "test_data = [(bert_word_to_embedding[x], bert_word_to_embedding[y], z, word_to_index[x], word_to_index[y]) for x,y,z in test_pairs]\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "bert_probe.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "per_word_total = dict.fromkeys(bert_word_to_embedding, 0)\n",
    "per_word_correct = dict.fromkeys(bert_word_to_embedding, 0)\n",
    "\n",
    "tp_bert = 0\n",
    "fp_bert = 0\n",
    "tn_bert = 0\n",
    "fn_bert = 0\n",
    "\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    \n",
    "    obj = batch[0]\n",
    "    affordance = batch[1]\n",
    "    target = batch[2]\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        \n",
    "        output = bert_probe(obj, affordance)\n",
    "        \n",
    "        bert_loss = criterion(output, target)\n",
    "        test_loss += bert_loss.item()\n",
    "\n",
    "        # Calculate total accuracy\n",
    "        total += len(batch[0])\n",
    "        \n",
    "        prediction = torch.argmax(output, dim=1)\n",
    "        correct_predictions = torch.eq(prediction,target).long()\n",
    "        correct += float(sum(correct_predictions))\n",
    "\n",
    "        # Calculate per-object and per-affordance accuracy\n",
    "        object_indices = batch[3].tolist()\n",
    "        objects = [index_to_word[i] for i in object_indices]\n",
    "        affordance_indices = batch[4].tolist()\n",
    "        affordances = [index_to_word[i] for i in affordance_indices]\n",
    "        \n",
    "        for n,word in enumerate(objects):\n",
    "            if prediction[n] == target[n]:\n",
    "                per_word_correct[word] += 1\n",
    "            per_word_total[word] += 1\n",
    "            \n",
    "        for n,word in enumerate(affordances):\n",
    "            if prediction[n] == target[n]:\n",
    "                per_word_correct[word] += 1\n",
    "            per_word_total[word] += 1\n",
    "            \n",
    "        # Calculate tp,fp,tn,fn\n",
    "        for i, value in enumerate(prediction.tolist()):\n",
    "            if target.tolist()[i] == 1 and prediction.tolist()[i] == 1:\n",
    "                tp_bert += 1\n",
    "            elif target.tolist()[i] == 0 and prediction.tolist()[i] == 1:\n",
    "                fp_bert += 1\n",
    "            elif target.tolist()[i] == 1 and prediction.tolist()[i] == 0:\n",
    "                fn_bert += 1\n",
    "            elif target.tolist()[i] == 0 and prediction.tolist()[i] == 0:\n",
    "                tn_bert += 1\n",
    "        \n",
    "\n",
    "        print('>', np.round(test_loss/(i+1), 4))\n",
    "\n",
    "accuracy_bert_probe = correct / total\n",
    "per_object_accuracy_bert_probe = {word : (per_word_correct[word] / per_word_total[word]) for word in unique_objects if per_word_total[word] > 0}\n",
    "per_affordance_accuracy_bert_probe = {word : (per_word_correct[word] / per_word_total[word]) for word in unique_affordances if per_word_total[word] > 0}\n",
    "\n",
    "print()\n",
    "print(f'Total accuracy BERT probe: {np.round(accuracy_bert_probe * 100, 2)} %')\n",
    "print()\n",
    "\n",
    "print('Per-object accuracy BERT probe:')\n",
    "for k,v in per_object_accuracy_bert_probe.items():\n",
    "    print(f'{k} : {np.round(v * 100, 2)} %')\n",
    "print()\n",
    "    \n",
    "print('Per-affordance accuracy BERT probe:')\n",
    "for k,v in per_affordance_accuracy_bert_probe.items():\n",
    "    print(f'{k} : {np.round(v * 100, 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bert = (tp_bert + tn_bert) / (tp_bert + fp_bert + tn_bert + fn_bert)\n",
    "print(f'{np.round(accuracy_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_bert = tp_bert / (tp_bert + fp_bert)\n",
    "print(f'{np.round(precision_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_bert = tp_bert / (tp_bert + fn_bert)\n",
    "print(f'{np.round(recall_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_bert = (2 * recall_bert * precision_bert) / (recall_bert + precision_bert)\n",
    "print(f'{np.round(f1_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the BERT Probe on seen objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for affordance in unique_affordances:\n",
    "        output = bert_probe(bert_word_to_embedding['sickle'].unsqueeze(0), bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print('sickle, carving knife')\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        output = bert_probe(bert_word_to_embedding['carving knife'].unsqueeze(0), bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        print()\n",
    "    \n",
    "    for affordance in unique_affordances:\n",
    "        output = bert_probe(bert_word_to_embedding['banjo'].unsqueeze(0), bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print('banjo, guitar')\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        output = bert_probe(bert_word_to_embedding['guitar'].unsqueeze(0), bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        print()\n",
    "        \n",
    "    for affordance in unique_affordances:\n",
    "        output = bert_probe(bert_word_to_embedding['small boat'].unsqueeze(0), bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print('small boat, kayak')\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        output = bert_probe(bert_word_to_embedding['kayak'].unsqueeze(0), bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the VisualBERT Probe on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_bert_probe = Probe()\n",
    "visual_bert_probe.load_state_dict(torch.load(\"model_visual_bert_probe|epochs_2000|batch_size_64|learning_rate_0.005\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_bert_probe = visual_bert_probe.to(device)\n",
    "test_loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "visual_bert_probe.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "per_word_total = dict.fromkeys(visual_bert_word_to_embedding, 0)\n",
    "per_word_correct = dict.fromkeys(visual_bert_word_to_embedding, 0)\n",
    "\n",
    "tp_visual_bert = 0\n",
    "fp_visual_bert = 0\n",
    "tn_visual_bert = 0\n",
    "fn_visual_bert = 0\n",
    "\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    \n",
    "    obj = batch[2]\n",
    "    affordance = batch[3]\n",
    "    target = batch[4]\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        \n",
    "        output = visual_bert_probe(obj, affordance)\n",
    "        \n",
    "        visual_bert_loss = criterion(output, target)\n",
    "        test_loss += visual_bert_loss.item()\n",
    "\n",
    "        # Calculate total accuracy\n",
    "        total += len(batch[0])\n",
    "        \n",
    "        prediction = torch.argmax(output, dim=1)\n",
    "        correct_predictions = torch.eq(prediction,target).long()\n",
    "        correct += float(sum(correct_predictions))\n",
    "\n",
    "        # Calculate per word accuracy\n",
    "        object_indices = batch[5].tolist()\n",
    "        objects = [index_to_word[i] for i in object_indices]\n",
    "        affordance_indices = batch[6].tolist()\n",
    "        affordances = [index_to_word[i] for i in affordance_indices]\n",
    "        \n",
    "        for n,word in enumerate(objects):\n",
    "            if prediction[n] == target[n]:\n",
    "                per_word_correct[word] += 1\n",
    "            per_word_total[word] += 1\n",
    "            \n",
    "        for n,word in enumerate(affordances):\n",
    "            if prediction[n] == target[n]:\n",
    "                per_word_correct[word] += 1\n",
    "            per_word_total[word] += 1\n",
    "            \n",
    "        # Calculate tp,fp,tn,fn\n",
    "        for i, value in enumerate(prediction.tolist()):\n",
    "            if target.tolist()[i] == 1 and prediction.tolist()[i] == 1:\n",
    "                tp_visual_bert += 1\n",
    "            elif target.tolist()[i] == 0 and prediction.tolist()[i] == 1:\n",
    "                fp_visual_bert += 1\n",
    "            elif target.tolist()[i] == 1 and prediction.tolist()[i] == 0:\n",
    "                fn_visual_bert += 1\n",
    "            elif target.tolist()[i] == 0 and prediction.tolist()[i] == 0:\n",
    "                tn_visual_bert += 1\n",
    "\n",
    "        print('>', np.round(test_loss/(i+1), 4))\n",
    "\n",
    "accuracy_visual_bert_probe = correct / total\n",
    "per_object_accuracy_visual_bert_probe = {word : (per_word_correct[word] / per_word_total[word]) for word in unique_objects if per_word_total[word] > 0}\n",
    "per_affordance_accuracy_visual_bert_probe = {word : (per_word_correct[word] / per_word_total[word]) for word in unique_affordances if per_word_total[word] > 0}\n",
    "\n",
    "print(f'Total accuracy VisualBERT probe: {np.round(accuracy_visual_bert_probe * 100, 2)} %')\n",
    "print()\n",
    "\n",
    "print('Per-object accuracy VisualBERT probe:')\n",
    "for k,v in per_object_accuracy_visual_bert_probe.items():\n",
    "    print(f'{k} : {np.round(v * 100, 2)} %')\n",
    "print()\n",
    "\n",
    "print('Per-affordance accuracy VisualBERT probe:')\n",
    "for k,v in per_affordance_accuracy_visual_bert_probe.items():\n",
    "    print(f'{k} : {np.round(v * 100, 2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_visual_bert = (tp_visual_bert + tn_visual_bert) / (tp_visual_bert + fp_visual_bert + tn_visual_bert + fn_visual_bert)\n",
    "print(f'{np.round(accuracy_visual_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_visual_bert = tp_visual_bert / (tp_visual_bert + fp_visual_bert)\n",
    "print(f'{np.round(precision_visual_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_visual_bert = tp_visual_bert / (tp_visual_bert + fn_visual_bert)\n",
    "print(f'{np.round(recall_visual_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_visual_bert = (2 * recall_visual_bert * precision_visual_bert) / (recall_visual_bert + precision_visual_bert)\n",
    "print(f'{np.round(f1_visual_bert * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the VisualBERT Probe on seen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for affordance in unique_affordances:\n",
    "        output = visual_bert_probe(visual_bert_word_to_embedding['sickle'].unsqueeze(0), visual_bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print('sickle, carving knife')\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        output = visual_bert_probe(visual_bert_word_to_embedding['carving knife'].unsqueeze(0), visual_bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        print()\n",
    "    \n",
    "    for affordance in unique_affordances:\n",
    "        output = visual_bert_probe(visual_bert_word_to_embedding['banjo'].unsqueeze(0), visual_bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print('banjo, guitar')\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        output = visual_bert_probe(visual_bert_word_to_embedding['guitar'].unsqueeze(0), visual_bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        print()\n",
    "        \n",
    "    for affordance in unique_affordances:\n",
    "        output = visual_bert_probe(visual_bert_word_to_embedding['small boat'].unsqueeze(0), visual_bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print('small boat, kayak')\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        output = visual_bert_probe(visual_bert_word_to_embedding['kayak'].unsqueeze(0), visual_bert_word_to_embedding[affordance].unsqueeze(0))\n",
    "        print(f'{affordance}: {torch.argmax(output)}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
